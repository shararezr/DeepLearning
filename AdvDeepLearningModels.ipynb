{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**"
      ],
      "metadata": {
        "id": "kLUM7s0GD7EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Hyperparameters\n",
        "\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "number_epochs = 60\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "\n",
        "#Toy DataSet\n",
        "\n",
        "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],\n",
        "                    [9.779], [6.182], [7.59], [2.167], [7.042],\n",
        "                    [10.791], [5.313], [7.997], [3.1]],dtype= np.float32)\n",
        "\n",
        "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573],\n",
        "                    [3.366], [2.596], [2.53], [1.221], [2.827],\n",
        "                    [3.465], [1.65], [2.904], [1.3]], dtype= np.float32)\n",
        "\n",
        "# Linear regression model\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "#loss and optimizar\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "#Train the model\n",
        "loss = 0\n",
        "for epoch in range(number_epochs):\n",
        "\n",
        "  #convert numpy arrays to tensors\n",
        "  inputs = torch.from_numpy(x_train)\n",
        "  targets = torch.from_numpy(y_train)\n",
        "\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, targets)\n",
        "\n",
        "  #backward propagation and optimize\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch+1) % 5 == 0:\n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, number_epochs, loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "#Plot the graph\n",
        "predicted = model(torch.from_numpy(x_train)).detach.numpy()\n",
        "plt.plot(x_train, y_train, 'ro', label= 'Original data')\n",
        "plt.plot(x_train, predicted, label = 'Fitted line')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(),'model.ckpt')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CC3VK0Bvln2-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**"
      ],
      "metadata": {
        "id": "Ehaludi-EBJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "number_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "input_size = 28*28\n",
        "\n",
        "\n",
        "## MNIST Dataset (images and labels)\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                        train=True,\n",
        "                                        transform= transforms.ToTensor(),\n",
        "                                        download=True)\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                       train=False,\n",
        "                                       transform=transforms.ToTesnor(),\n",
        "                                       download=True)\n",
        "\n",
        "\n",
        "\n",
        "#Data loader (input pipline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True\n",
        "                                           )\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False)\n",
        "\n",
        "\n",
        "\n",
        "#Logistic Regression Model\n",
        "model = nn.Linear(input_size, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "#loss and optimizer\n",
        "# nn.CrossEntropyLoss() computes softmax internally\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "\n",
        "#Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(number_epochs):\n",
        "\n",
        "  for i, (image,target) in enumerate(train_loader):\n",
        "\n",
        "        # Reshape images to (batch_size, input_size)\n",
        "        images = images.reshape(-1, input_size)\n",
        "        output = model(input)\n",
        "        loss = criterion(output,target)\n",
        "\n",
        "        #Backward and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "          print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                 .format(epoch+1, number_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "#Test the model\n",
        "#In test phase, we don't need to compute the gradient\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.shape(-1, input_size)\n",
        "    outputs = model(images)\n",
        "    _ , predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "  print('Accuracy of the model on the 10000 text images: {}%'.format(100* correct/total))\n",
        "\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6RsB3iep4S4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feedforward_Neural_Network**"
      ],
      "metadata": {
        "id": "69rkfTBtZV7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "\n",
        "#Device configuration\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "input_size = 28*28\n",
        "hidden_size = 500\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# MNIST DataSet (images, labels)\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                        train = True,\n",
        "                                        transform = transforms.ToTensor(),\n",
        "                                        download = True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                       train = False,\n",
        "                                       transform = transforms.ToTensor(),\n",
        "                                       download = True)\n",
        "\n",
        "\n",
        "#DataLoader (Data Pipline)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False)\n",
        "\n",
        "\n",
        "\n",
        "#Fully conected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "#calling the model (FeedForward Neural Network)\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "\n",
        "#Train the model\n",
        "Total_steps = len(train_loader)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,targets) in enumerate(train_loader):\n",
        "\n",
        "    #Move tensors to the configured device\n",
        "    inputs = images.reshape(-1,input_size).to(device)\n",
        "    labels = targets.to(device)\n",
        "\n",
        "\n",
        "    #Forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs,labels)\n",
        "\n",
        "\n",
        "    #Backward and Optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if (i+1)%100 ==0:\n",
        "      print('Epoch[{}/{}], Step[{}/{}], Loss: {:.4f}'\n",
        "      .format(epoch+1, num_epochs, i+1, Total_steps, loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "#Test the model\n",
        "#In test phase, we don't need to compute the gradients(for memory efficiency)\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images= images.reshape(-1,input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _ , predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "\n",
        "\n",
        "#Save the model checkpoint\n",
        "torch.save(model.state_dict(),'model.ckpt')\n",
        "\n"
      ],
      "metadata": {
        "id": "ZBTYhOiPZjUp",
        "outputId": "6b819e4e-3fe3-444b-8944-a008d50ace1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1/5], Step[100/600], Loss: 0.4934\n",
            "Epoch[1/5], Step[200/600], Loss: 0.3000\n",
            "Epoch[1/5], Step[300/600], Loss: 0.3203\n",
            "Epoch[1/5], Step[400/600], Loss: 0.1805\n",
            "Epoch[1/5], Step[500/600], Loss: 0.0965\n",
            "Epoch[1/5], Step[600/600], Loss: 0.1907\n",
            "Epoch[2/5], Step[100/600], Loss: 0.0762\n",
            "Epoch[2/5], Step[200/600], Loss: 0.0525\n",
            "Epoch[2/5], Step[300/600], Loss: 0.1232\n",
            "Epoch[2/5], Step[400/600], Loss: 0.0830\n",
            "Epoch[2/5], Step[500/600], Loss: 0.2476\n",
            "Epoch[2/5], Step[600/600], Loss: 0.0931\n",
            "Epoch[3/5], Step[100/600], Loss: 0.0366\n",
            "Epoch[3/5], Step[200/600], Loss: 0.0419\n",
            "Epoch[3/5], Step[300/600], Loss: 0.1308\n",
            "Epoch[3/5], Step[400/600], Loss: 0.1272\n",
            "Epoch[3/5], Step[500/600], Loss: 0.0857\n",
            "Epoch[3/5], Step[600/600], Loss: 0.1357\n",
            "Epoch[4/5], Step[100/600], Loss: 0.0624\n",
            "Epoch[4/5], Step[200/600], Loss: 0.0449\n",
            "Epoch[4/5], Step[300/600], Loss: 0.0162\n",
            "Epoch[4/5], Step[400/600], Loss: 0.0579\n",
            "Epoch[4/5], Step[500/600], Loss: 0.1076\n",
            "Epoch[4/5], Step[600/600], Loss: 0.0265\n",
            "Epoch[5/5], Step[100/600], Loss: 0.0172\n",
            "Epoch[5/5], Step[200/600], Loss: 0.0303\n",
            "Epoch[5/5], Step[300/600], Loss: 0.0158\n",
            "Epoch[5/5], Step[400/600], Loss: 0.0250\n",
            "Epoch[5/5], Step[500/600], Loss: 0.0927\n",
            "Epoch[5/5], Step[600/600], Loss: 0.0169\n",
            "Accuracy of the network on the 10000 test images: 97.78 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convolutional Neural Network**\n",
        "\n",
        "### Formula for output dimensions after convolution:\n",
        "\n",
        "\n",
        "Output Size (H, W)=  ((Input_Size(H,W)+ 2*Padding - Kernel Size) / Stride) +1\n",
        "\n",
        "\n",
        "### Formula for output dimensions after pooling:\n",
        "\n",
        "Output Size (H,W)= ((Input Size (H,W) - Kernel Size)/ Stride) + 1"
      ],
      "metadata": {
        "id": "YZMkJO3rvy7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Device Configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 60\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "input_size = 28*28\n",
        "hidden_size = 100\n",
        "\n",
        "\n",
        "#MNIST Dataset\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                        train = True,\n",
        "                                        transform = transforms.ToTensor(),\n",
        "                                        download = True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                       train = True,\n",
        "                                       transform = transforms.ToTensor(),\n",
        "                                       download = True)\n",
        "\n",
        "#DataLoader (Data Pipline)\n",
        "\n",
        "train_loader = DataLoader(dataset = train_data, batch_size = batch_size , shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(dataset = test_data, batch_size = batch_size , shuffle = False)\n",
        "\n",
        "\n",
        "#Convolutional neural network (two convolutional layers)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.layer1= nn.Sequential(\n",
        "        nn.Conv2d(1, 16, kernel_size=5, stride=1, padding= 2),\n",
        "        nn.BatchNormal2d(16),\n",
        "        nn.Relu(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(16, 32, kernel_size= 5, stride=1, padding=2),\n",
        "        nn.BatchNormal2d(16),\n",
        "        nn.Relu(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc = nn.Linear(7*7*32, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "#Optimizar and loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "model = ConvNet(num_classes).to(device)\n",
        "\n",
        "\n",
        "#Train the model\n",
        "total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "\n",
        "    #Move tensors to the configured device\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    #Forward Phase\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs,labels)\n",
        "\n",
        "    ## Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 == 0 :\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_steps, loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Test the model\n",
        "#In test phase, we don't need to compute the gradients(for memory efficiency)\n",
        "with torch.no_grad():\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _ , predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: {}%'.format(100 *correct / total))\n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "\n",
        "#Save the model checkpoint\n",
        "torch.save(model.state_dict(),'model.ckpt')\n"
      ],
      "metadata": {
        "id": "DEe-9V-orHqi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Residual Network**"
      ],
      "metadata": {
        "id": "WcQ3oi4YAdPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "\n",
        "#Device Configuration\n",
        "#device =. torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "num_epochs = 80\n",
        "\n",
        "#Image Preprocessing modules (Transformers)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#CIFAR10 Dataset\n",
        "train_data = torchvision.datasets.CIFAR10(root = '../../data',\n",
        "                                         train = True,\n",
        "                                         transform = transform,\n",
        "                                         download = True)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(root = '../../data',\n",
        "                                        train = False,\n",
        "                                        transform = transform,\n",
        "                                        download = True)\n",
        "\n",
        "\n",
        "\n",
        "#DataLoader (Pipline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True,\n",
        "                                           )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True,\n",
        "                                           )\n",
        "\n",
        "\n",
        "#Residual Networks Model\n",
        "\n",
        "\n",
        "# first we define the 3*3 convolution\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "  return nn.Conv2d(in_channels out_channels, kernel_size=5, stride = stride,  padding = 1, bias = False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#We Define Residual Block\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = conv3x3(out_channels, out_channels)\n",
        "    self.bn2 = nn.BatchNormal2d(out_channels)\n",
        "    self.downsample = downsample\n",
        "\n",
        "  def forward(self,x):\n",
        "    residual = x\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    if self.downsample:\n",
        "      residual = self.downsample(x)\n",
        "    out += residual\n",
        "    out = self.relu(out)\n",
        "    return out\n",
        "\n",
        "#Then we define ResNet\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_channels = 16\n",
        "    self.conv = conv3x3(3, 16)\n",
        "    self.bn = nn.BatchNorm2d(16)\n",
        "    self.relu = nn.ReLU(inplace = True)\n",
        "    self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "    self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "    self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "    self.avg_pool = nn.AvgPool2d(8)\n",
        "    self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "  def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "    downsample = None\n",
        "    if (stride != 1) or (self.in_chnnels != out_channels):\n",
        "      downsample = nn.sequential(\n",
        "          conv3x3(self.in_channels, out_channels, stride = stride),\n",
        "          nn.BatchNorm2d(out_channels))\n",
        "      layers = []\n",
        "      layers.append(block(self.in_channels, out_channels, stride,downsample))\n",
        "      self.in_channels. = out_channels\n",
        "      for i in range(1, blocks):\n",
        "        layers.append(block(out_channels, out_channels))\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "#calling the model\n",
        "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
        "\n",
        "\n",
        "#Optimizer and Loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "#Update Learning Rate\n",
        "def update_lr(optimizer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr\n",
        "\n",
        "\n",
        "\n",
        "#Train the model\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "\n",
        "    #Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    #Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "      .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    if (epoch+1)%20 == 0:\n",
        "      curr_lr /= 3\n",
        "      update_lr(optimizer, curr_lr)\n",
        "\n",
        "\n",
        "\n",
        "#Test the model\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the model on the test images: {}%'.format(100*correct/total))\n",
        "\n",
        "\n",
        "#save the model checkpoint\n",
        "torch.save(model.state_dict(), 'resnet.ckpt')\n"
      ],
      "metadata": {
        "id": "qBQHQDJ5zr4t",
        "outputId": "4a13faa2-f00a-44e3-fe53-0f92e425dbcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:11<00:00, 14.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/cifar-10-python.tar.gz to ../../data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recurrent Neural Network**"
      ],
      "metadata": {
        "id": "TRE54Ofu0o67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#Device Configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Hyperparametes\n",
        "sequence_length = 28\n",
        "input_size = 28\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "num_epochs = 2\n",
        "learning_rate  = 0.01\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root = '../../root',\n",
        "                                           train = True,\n",
        "                                           transform = transforms.ToTensor(),\n",
        "                                           download = True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root = '../../root',\n",
        "                                          train = False,\n",
        "                                          transform = transforms.ToTensor(),\n",
        "                                          download = True)\n",
        "\n",
        "# Data Loader\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "Test_loader = torch.utils.data.DataLoader(dataset = test_datatset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Model Recurrent Neural Network (Many to one)\n",
        "class RNN(nn.Mudole):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "      #set initial hidden and cell states\n",
        "      h0 = torch.zeros(self.num_layers, x_size(0), self.hidden_size).to(device)\n",
        "      c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "\n",
        "      #Forward Propagate LSTM\n",
        "      out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "      # Decode the hidden state of the last time step\n",
        "      out = self.fc(out[:, -1, :])\n",
        "      return out\n",
        "\n",
        "\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#optimizer and loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Train the model\n",
        "Total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for i,(images, targets) in enumerate(train_loader):\n",
        "    #Trnasfer the train data into the device in a suitable shape\n",
        "    images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "    labels = targets.to(devie)\n",
        "\n",
        "\n",
        "\n",
        "    #Outputs\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    #Optimize and backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 == 0 :\n",
        "      print('Epochs[{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "      .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Test the model\n",
        "\n",
        "model.evel()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for images,targets in test_loader:\n",
        "\n",
        "    images = images.reshape(-1,sequence_length,input_size).to(device)\n",
        "    labels = targets.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "  print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "\n",
        "#Save the model\n",
        "torch.save(model.state_dict(), 'model.ckpt')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qDqIE_zGGmXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bidirectional Recurrent Neural Network**"
      ],
      "metadata": {
        "id": "2xGPf4N2-4Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Dvice Configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "\n",
        "sequence_length = 28\n",
        "input_size = 28\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_epochs = 2\n",
        "batch_size = 70\n",
        "learning_rate = 0.003\n",
        "num_classes =10\n",
        "\n",
        "\n",
        "\n",
        "#Dataset\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                        train = True,\n",
        "                                        transforms = transforms.ToTensor(),\n",
        "                                        download = True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                       train = False,\n",
        "                                       transforms = transforms.ToTensor(),\n",
        "                                       download = True)\n",
        "\n",
        "#DataLoader (Pipline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                           batch_size =batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader =torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                         batch_size = batch_size\n",
        "                                         shuffle =False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Bidirectional recurrent neural network(many-to-one)\n",
        "\n",
        "class BiRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(BiRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional = True)\n",
        "    slef.fc = nn.Linear(hidden_size*2, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    #set the initial states\n",
        "    h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_layers).to(device)\n",
        "    c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_layers).to(device)\n",
        "\n",
        "\n",
        "    #Forward Propagate LSTM\n",
        "\n",
        "    out, _ = self.lstm(x,(h0,c0))\n",
        "\n",
        "\n",
        "    # Decode the hidden state of the last time step\n",
        "    out = self.fc(out[:,-1,:])\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "#optimizer and loss\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "#Train the model\n",
        "\n",
        "total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "    #transfer data into the model\n",
        "    images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    #prediction and loss value\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs,labels)\n",
        "\n",
        "    #Optimization and Backward propagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  print('Epoch [{}/{}], Step [{}/{}], Loss {:.4f}'.format(epoch_1, num_epochs, i+1, total_steps, loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "#Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for images,labels in test_loader:\n",
        "\n",
        "    images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of the model on 1000 test images: {}%'.format(100*correct/total))\n",
        "\n",
        "#save the model\n",
        "torch.save(model.state_dict, 'model.ckpt')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pIi1VotdE-mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **language_model**"
      ],
      "metadata": {
        "id": "Ux_-QFqaRdpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from data_utils import Dictionary, Corpus\n",
        "\n",
        "#Device_Configuration\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "num_epochs =  5\n",
        "embed_size = 128\n",
        "hidden_size = 1024\n",
        "num_samples = 1000     # number of words to be sampled\n",
        "num_layers = 1\n",
        "batch_size = 20\n",
        "learning_rate = 0.002\n",
        "seq_length = 30\n",
        "\n",
        "\n",
        "#Load \"Penn Treebank\" dataset\n",
        "corpus = Corpus()\n",
        "ids = corpus.get_data('data/train.txt', batch_size)\n",
        "vocab_size  = len(corpus.dictionary)\n",
        "num_batches = ids.size(1) // seq_length\n",
        "\n",
        "\n",
        "\n",
        "#RNN based Language Model\n",
        "class RNNLM(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, num_layers, hidden_size):\n",
        "    super(RNNLM,self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "    self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.linear = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    #Embed word ids to vectors\n",
        "    x = self.embed(x)\n",
        "\n",
        "\n",
        "    #Forward Propagate LSTM\n",
        "    out, (h, c) = self.lstm(x, h)\n",
        "\n",
        "    #Linear forward,  Reshape output to (batch_size*sequence_length, hidden_size)\n",
        "    out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
        "\n",
        "    #Decode hidden states of all time steps\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out, (h, c)\n",
        "\n",
        "\n",
        "model = RNNLM(vocab_size, embed_size, num_layers, hidden_size)\n",
        "\n",
        "\n",
        "#Optimizer and loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Truncated backpropagation\n",
        "def detach(states):\n",
        "  return [state.detach() for state in states]\n",
        "\n",
        "#Train the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  #Set initial hidden and cell states\n",
        "  states = (torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
        "            torch.zeros(num_layers, batch_size, hidden_szie).to(device))\n",
        "\n",
        "\n",
        "  for i in range(0, ids.size(1)-seq_length,seq_length):\n",
        "    #Get mini_batch inputs and outputs\n",
        "    inputs = ids[:,i,i+seq_length].to(device)\n",
        "    targets = ids[:,i+1,i+1+seq_length].to(device)\n",
        "\n",
        "\n",
        "    #states, Forward phase\n",
        "    states = detach(states)\n",
        "    outputs, states = model(inputs,states)\n",
        "    loss = criterion(outputs, targets.reshape(-1))\n",
        "\n",
        "    #Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    #prevent explodig gradients and vanishing gradients\n",
        "    clip_grad_norm_(model.parameters(),0.5)\n",
        "    optimizer.step()\n",
        "\n",
        "    step = (i+1) // seq_length\n",
        "\n",
        "    if(step%100 ==0):\n",
        "      print('Epoch [{}/{}], Step [{}/[]], loss:{.4f}'.format(\n",
        "          epoch+1, num_batches, step, total_step, loss.item(), np.exp(loss.item())))\n",
        "\n",
        "\n",
        "#Test the Model\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  with open('sample.txt', 'w') as f:\n",
        "    #set initial hidden and cell states\n",
        "    state = (torch.zeros(num_layers, 1, hidden_size).to(device),\n",
        "             torch.zeros(num_layers, 1, hidden_size).to(device))\n",
        "\n",
        "    #Select one word id randomly\n",
        "    prob = torch.ones(vocab_size)\n",
        "    input = torch.multinomial(prob,num_samples=1).unsqueeze(1).to(device)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "\n",
        "      #Forward propagate RNN\n",
        "      output, state = model(input, state)\n",
        "\n",
        "      #Sample a word id\n",
        "      prob = output.exp()\n",
        "      word_id = torch.multinomial(prob, num_samples=1).item()\n",
        "\n",
        "      #Fill input with sampled word id for the next time step\n",
        "      input.fill(word_id)\n",
        "\n",
        "      #File write\n",
        "      word = curpus.dictionary.idx2word[word_id]\n",
        "      word = '\\n' if word == '<eos>' else word + ' '\n",
        "      f.write(word)\n",
        "\n",
        "\n",
        "      if (i+1) % 100 == 0:\n",
        "        print('Sampled [{}/{}] words and save to {}'.format(i+1, num_samples, 'sample.txt'))\n",
        "\n",
        "\n",
        "\n",
        "#Save the model checkpoints\n",
        "torch.save(model.state_dict(), 'model.ckpt')\n"
      ],
      "metadata": {
        "id": "kzgTFioSlih4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generative Adverserial Network**"
      ],
      "metadata": {
        "id": "NW3qniWoP1-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn\n",
        "import os\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "#Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.001\n",
        "latent_size = 64\n",
        "hidden_size = 256\n",
        "image_size = 784\n",
        "num_epochs = 200\n",
        "batch_size = 100\n",
        "sample_dir = 'samples'\n",
        "\n",
        "\n",
        "#Create a directory if not exists\n",
        "if not os.path.exists(sample_dir):\n",
        "  os.makedirs(sample_dir)\n",
        "\n",
        "\n",
        "# Image processing\n",
        "# transform = transforms.Compose([\n",
        "#                 transforms.ToTensor(),\n",
        "#                 transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
        "#                                      std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "#Image processing.   # 1 for greyscale channels\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std = [0,5])\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "#MNIST dataset\n",
        "mnist = torchvision.datasets.MNIST(root = '../../data/',\n",
        "                                   train=True,\n",
        "                                   transform = transform,\n",
        "                                   download = True)\n",
        "\n",
        "\n",
        "\n",
        "#DataLoader\n",
        "data_loader = torch.utils.data.DataLoader(dataset = mnist,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle =True)\n",
        "\n",
        "\n",
        "#Discriminator\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(image_size, hidden_size),\n",
        "    nn.LeakyRelu(0.2),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.LeakyRelu(0.2),\n",
        "    nn.Linear(hidden_size, 1),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "#Generator\n",
        "G = nn.Sequential(\n",
        "    nn.Linear(latent_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, image_size),\n",
        "    nn.Tanh())\n",
        "\n",
        "\n",
        "#Device Setting\n",
        "D = D.to(device)\n",
        "G = G.to(device)\n",
        "\n",
        "\n",
        "#Binary_Cross Entropy Loss and Optimizer\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr = 0.0002)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr = 0.0002)\n",
        "\n",
        "\n",
        "#denorm\n",
        "def denorm(x):\n",
        "  out = (x+1) / 2\n",
        "  return out.clamp(0,1)\n",
        "\n",
        "\n",
        "def reset_grad():\n",
        "  d_optimizer.zero_grad()\n",
        "  g_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "#Starting Training\n",
        "total_step = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "  for i, (images, _) in enumerate(data_loader):\n",
        "\n",
        "    images = images.reshape(batch_size, -1).to(device)\n",
        "\n",
        "\n",
        "    # Create the labels which are later used as input for the BCE loss\n",
        "    real_labels = torch.zeros(batch_size, 1).to(device)\n",
        "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "    #################Train the discriminator################\n",
        "    #Compute the BCE Loss using realimages where BCE_Loss(x,y): -y * log(D(x)) - (1 - y)* log(1 - D(x))\n",
        "    #Second term of the loss is always zero since real_labels == 1\n",
        "\n",
        "    outputs = D(images)\n",
        "    d_loss_real = criterion(outputs, real_labels)\n",
        "    real_score = outputs\n",
        "\n",
        "    #Compute BCELoss using Fake Images\n",
        "    #First term of the loss is always zero since fake_labels === 0\n",
        "\n",
        "    z = torch.randn(batch_size, latent_size).to(device)\n",
        "    fake_images = G(z)\n",
        "    outputs = D(fake_images)\n",
        "    d_loss_fake = criterion(outputs, fake_labels)\n",
        "    fake_score = outputs\n",
        "\n",
        "    #Backprop and optimize\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    reset_grad()\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "\n",
        "    ###############Train the generator#############\n",
        "\n",
        "    #Compute the loss with fake images\n",
        "    #Instead of minimizing log(1-(D(G(x))), we try to maximize log(D(G(x))) by training G(x)!\n",
        "    g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "    #Backprop and optimize\n",
        "    reset_grad()\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    if(i+1) % 200 == 0:\n",
        "      print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'\n",
        "      .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(),\n",
        "              real_score.mean().item(), fake_score.mean().item()))\n",
        "\n",
        "\n",
        "\n",
        "  #Save the real images\n",
        "  if (epoch+1) == 1:\n",
        "    images = images.reshape(images.size(0), 1, 28, 28)\n",
        "    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
        "\n",
        "\n",
        "   # Save sampled images\n",
        "   fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
        "   save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
        "\n",
        "# Save the model checkpoints\n",
        "torch.save(G.state_dict(), 'G.ckpt')\n",
        "torch.save(D.state_dict(), 'D.ckpt')\n",
        ""
      ],
      "metadata": {
        "id": "jjKPkfqnQBpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variational Autoencoder**"
      ],
      "metadata": {
        "id": "MYVItb-Hw90Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "#Device Configuration\n",
        "device = torch.device('cuda' torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Create a directory if not exist\n",
        "sample_dir = 'samples'\n",
        "if not os.path.exists(sample_dir):\n",
        "  os.makedirs(sample_dir)\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "image_size = 28*28\n",
        "h_dim = 400\n",
        "z_dim = 20\n",
        "num_epochs = 15\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "\n",
        "# MNIST dataset\n",
        "train_data = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                        train = True,\n",
        "                                        transform = transforms.ToTensor(),\n",
        "                                        download = True)\n",
        "\n",
        "#DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "# VAE model\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self,image_size= 784, h_dim = 400, z_dim = 20):\n",
        "    super(VAE, self).__init__()\n",
        "    self.fc1 = nn.Linear(image_size, h_dim)\n",
        "    self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "    self.fc3 = nn.Linear(h_dim, z_dim)\n",
        "    self.fc4 = nn.Linear(z_dim, h_dim)\n",
        "    self.fc5 = nn.Linear(h_dim, image_size)\n",
        "\n",
        "  def encode(self, x):\n",
        "    h = F.relu(self.fc1(x))\n",
        "    return self.fc2(h), self.fc3(h)\n",
        "\n",
        "  def reparameterize(self, mu, log_var):\n",
        "    std = torch.exp(log_var/2)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + eps * std\n",
        "\n",
        "  def decode(self,z):\n",
        "    h = F.relu(self.fc4(z))\n",
        "    return F.sigmoid(self.fc5(h))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    mu, log_var = self.encode(x)\n",
        "    z = self.reparameterize(mu, log_var)\n",
        "    x_reconst = self.decode(z)\n",
        "    return x_reconst, mu, log_var\n",
        "\n",
        "\n",
        "#Optimizer and Calling model\n",
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#Training the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for i,(x,_) in enumerate(train_loader):\n",
        "\n",
        "    #Forward pass\n",
        "    x = x.to(device).view(-1, image_size)\n",
        "    x_reconst, mu, log_var = model(x)\n",
        "\n",
        "    #Compute Reconstruction Loss and KL Divergence\n",
        "    #For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
        "    reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average= False)\n",
        "    kl_div = -0.5*torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "\n",
        "    #Backprop and optimize\n",
        "    loss = reconst_loss + kl_div\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 10 == 0 :\n",
        "      print('Epoch [{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, Kl Div: {:.4f}'\n",
        "            .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    #save the sampled images\n",
        "    z = torch.randn(batch_size, z_dim).to(device)\n",
        "    out = model.decode(z).view(-1,1,28,28)\n",
        "    save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
        "\n",
        "    #save the reconstructed images\n",
        "    out, _, _ = model(x)\n",
        "    x_concat = torch.cat([x.view(-1,1,28,28), out.view(-1, 1, 28, 28)], dim =3)\n",
        "    save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))\n",
        "\n"
      ],
      "metadata": {
        "id": "y1mcArauxyRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Style Learning**"
      ],
      "metadata": {
        "id": "4Ek57Caj6GQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "import numpy as np\n",
        "from PIL import image\n",
        "import argparse\n",
        "from __future__ import division\n",
        "\n",
        "\n",
        "#Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Loading images\n",
        "def load_image(image_path, transform = None, max_size = None, shape = None):\n",
        "  \"\"\"load an image and convert it to a torch tensor\"\"\"\n",
        "  image = Image.open(image_path)\n",
        "\n",
        "\n",
        "  if max_size:\n",
        "    scale = max_size/ max(image.size)\n",
        "    size = np.array(image.size)*scale\n",
        "    image = image.resize(size.astype(int), Image.ANTIALIAS)\n",
        "\n",
        "\n",
        "  if shape:\n",
        "    image = image.resize(shape, Image.LANCZOS)\n",
        "\n",
        "\n",
        "  if transform:\n",
        "    image = transform(image).unsqueeze(0)\n",
        "\n",
        "  return image.to(device)\n",
        "\n",
        "\n",
        "class VGGNet(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    \"\"\"Select conv1_1 ~ conv5_1 activation maps.\"\"\"\n",
        "    super(VGGNet, self).__init__()\n",
        "    self.select = ['0', '5', '10', '19', '28']\n",
        "    self.vgg = models19.vgg19(pretrained = True).features\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"Extract multiple convolutional feature maps.\"\"\"\n",
        "    features = []\n",
        "    for name, layers in self.vgg._modules.items():\n",
        "      x = layer(x)\n",
        "      if name in self.select:\n",
        "        features.append(x)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def main(config):\n",
        "\n",
        "    # Image preprocessing\n",
        "    # VGGNet was trained on ImageNet where images are normalized by mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\n",
        "    # We use the same normalization statistics here.\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean = (0.485, 0.456, 0.406),\n",
        "                                                         std = (0.229, 0.224, 0.225))])\n",
        "\n",
        "\n",
        "    # Load content and style images\n",
        "    # Make the style image same size as the content image\n",
        "\n",
        "    content = load_image(config.content, transform, max_size= config.max_size)\n",
        "    style = load_image(config.style, transform, shape= [content.size(2), content.size(3)])\n",
        "\n",
        "\n",
        "    # Initialize a target image with the content image\n",
        "    target = content.clone().requires_grad_(True)\n",
        "\n",
        "\n",
        "    #Optimizer and calling the model\n",
        "    optimizer  = torch.optim.Adam([target], lr = learning_rate, betas=[0.5, 0.999])\n",
        "    vgg = VGGNet().to(device).eval()\n",
        "\n",
        "\n",
        "    for step in range(config.total_step):\n",
        "\n",
        "      # Extract multiple(5) conv feature vectors\n",
        "      target_features = vgg(target)\n",
        "      style_features = vgg(style)\n",
        "      content_features = vgg(content)\n",
        "\n",
        "\n",
        "      style_loss = 0\n",
        "      content_loss = 0\n",
        "\n",
        "\n",
        "      for f1,f2,f3 in zip(target_features, content_features, style_features):\n",
        "\n",
        "        #Compute the content loss with target and content images\n",
        "        content_loss += torch.mean((f1 - f2)**2)\n",
        "\n",
        "        #Reshape Convolutional Feature Maps\n",
        "        _, c, h, w = f1.size()\n",
        "        f1 = f1.view(c, h*w)\n",
        "        f3 = f3.view(c, h*w)\n",
        "\n",
        "        #Compute the gram matrix between the feature maps of each images(style and content)\n",
        "        f1 = torch.mm(f1,f1.t())\n",
        "        f3 = torch.mm(f3,f3.t())\n",
        "\n",
        "        #Compute the style loss with target and style images\n",
        "        style_loss += torch.mean((f1-f3)**2) / c*h*w\n",
        "\n",
        "        #Compute total loss, Back Propagation, and Optimize\n",
        "        loss = content_loss + config.style_weight * style_loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if (step+1) % config.log_step == 0:\n",
        "          print('Step [{}/{}], Content Loss: {:.4f}, Style Loss: {:.4f}'\n",
        "                .format(step+1, config.total_step, content_loss.item(), style_loss.item()))\n",
        "\n",
        "        if (step+1) % config.sample_step == 0:\n",
        "          #save the generated image\n",
        "          denorm = transform.Normalize((-2.12, -2.04, -1.80),(4.37, 4.46, 4.44))\n",
        "          img = target.clone().squeeze()\n",
        "          img = denorm(img).clamp_(0,1)\n",
        "          torchvision.utils.save_image(img, 'output-{}.png'.format(step+1))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--content', type=str, default='png/content.png')\n",
        "    parser.add_argument('--style', type=str, default='png/style.png')\n",
        "    parser.add_argument('--max_size', type=int, default=400)\n",
        "    parser.add_argument('--total_step', type=int, default=2000)\n",
        "    parser.add_argument('--log_step', type=int, default=10)\n",
        "    parser.add_argument('--sample_step', type=int, default=500)\n",
        "    parser.add_argument('--style_weight', type=float, default=100)\n",
        "    parser.add_argument('--lr', type=float, default=0.003)\n",
        "    config = parser.parse_args()\n",
        "    print(config)\n",
        "    main(config)\n"
      ],
      "metadata": {
        "id": "wgrF7z-A6LLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Captioning**"
      ],
      "metadata": {
        "id": "lVpu9FgCOLEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "#define an Encoder to extract features from the images\n",
        "\n",
        "class EncoderCNN(nn.Module):\n",
        "  def __init__(self,embed_size):\n",
        "\n",
        "    \"\"\"Load the pretrained ResNet-152 model and replace top fc layer.\"\"\"\n",
        "    super(EncoderCNN, self).__init__()\n",
        "    resnet = models.resnet152(pretrained = True)\n",
        "\n",
        "    # delete the last fc layer.\n",
        "    modules = list(resnet.children())[:-1]\n",
        "    self.resnet = nn.Sequential(*modules)\n",
        "    self.linear = nn.Linear(resnet.fc.in_features, embed_size)\n",
        "    self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)\n",
        "\n",
        "    def forward(self, images):\n",
        "\n",
        "      \"\"\"Extract feature vectors from input images.\"\"\"\n",
        "      with torch.no_grad():\n",
        "        features = self.resnet(images)\n",
        "\n",
        "      features = features.reshape(features.size(0), -1)\n",
        "      features = self.bn(self.linear(features))\n",
        "      return features\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, embed_size, hidden_size, vocab_size, num_layers, max_seq_length= 20):\n",
        "    \"\"\"Set the hyper-parameters and build the layers.\"\"\"\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "    self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "    self.max_seg_length = max_seq_length\n",
        "\n",
        "\n",
        "    def forward(self, features, captions, lengths):\n",
        "      \"\"\"Decode image feature vectors and generates captions.\"\"\"\n",
        "      embeddings = self.embed(captions)\n",
        "      embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
        "      packed = pack_padded_sequence(embeddings, lengths, batch_first=True)\n",
        "      hiddens, _ = self.lstm(packed)\n",
        "      outputs = self.linear(hiddens[0])\n",
        "      return outputs\n",
        "\n",
        "    def sample(self, features, states=None):\n",
        "      \"\"\"Generate captions for given image features using greedy search\"\"\"\n",
        "      sampled_ids = []\n",
        "      inputs = features.unsqueeze(1)\n",
        "\n",
        "      for i in range(self.max_seq_length):\n",
        "\n",
        "        hiddens, states = self.lstm(inputs, states)\n",
        "        outputs = self.linear(hiddens.squeeze(1))\n",
        "        _, predicted = outputs.max(1)\n",
        "        sampled_ids.append(predicted)\n",
        "        inputs = self.embed(predicted)\n",
        "        inputs = inputs.unsqueeze(1)\n",
        "\n",
        "      sampled_ids = torch.stack(sampled_ids, 1)                # sampled_ids: (batch_size, max_seq_length)\n",
        "      return sampled_ids\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iD4u8DzKd1On"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}