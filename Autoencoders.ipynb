{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Deep Learning Homework 5: *Autoencoders***\n","### MSc Computer Science, Data Science, Cybersecurity Computer Engeneering @UniPD\n","### 2nd semester - 6 ECTS\n","### Prof. Alessandro Sperduti & Prof. Nicol√≤ Navarin and Dr. Luca Pasa\n","---\n","\n","\n","In this homework, we will deal with _dimensionality reduction_ and learn how to develop a simple _Autoencoder_.\n","In the first part, we will learn how to develop a simple shallow autoencoder, then we will develop a deep version. Finally, we will experiment with the application of autoencoder on denoising data task (denoising-autoencoder). "],"metadata":{"id":"t0mpjt4iviT7"}},{"cell_type":"markdown","source":["#Requirements"],"metadata":{"id":"13P337TxEdxJ"}},{"cell_type":"code","source":["!pip3 install datasets skorch pandas~=1.5 torch~=1.13 torchinfo torchdata~=0.5 torchtext~=0.14 torchvision~=0.14 torchaudio~=0.13 "],"metadata":{"id":"hB3KNA5EEfRl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Imports"],"metadata":{"id":"Q9mVL8QNEbDO"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torchinfo import summary\n","from torchvision.datasets import CIFAR10\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from timeit import default_timer as timer\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"2JFyWj4XEcaN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading\n","\n","We load the `CIFAR-10 dataset`, available from `torchvision.datasets`. This dataset is one of the most popular benckmark in the filed of Computer Vision. It consits of $10$ different classes, that represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. The dataset contains $50,000$ training images and $10,000$ images for testing. \n","\n","First, we will pre-process them with a `PreProcessing` fuction that works in the following way. The images are originally in RGB format, but we will convert them to grayscale for convenience. The value of each pixel is between $0$ and $255$, and it represents a point of an image of size $32\\times32$. We will normalize all values between $0$ and $1$, and we will flatten the $32\\times32$ images into vectors of size $1024$.\n","Moreover, since no validation set is defined, we split the train set in a validation set and a new test set.\n","Finally, we design a custom dataset class, derived from the standard `Dataset` class, that returns a PyTorch Dataset object, along with its noisy version. The Gaussian noise is tunable with the `noise_factor` parameter and will be used for the Denoising Autoencoder."],"metadata":{"id":"6idwZhXTEYZx"}},{"cell_type":"code","source":["to_tensor = transforms.ToTensor()\n","\n","def PreProcessing(img):\n","  img = to_tensor(img) #PIL to tensor + Scaling\n","  img = torch.mean(img, 0) #One channel averaged over the colors\n","  img = img.reshape(torch.prod(torch.tensor(img.shape))) #Flattening\n","  return img.to(torch.float32)"],"metadata":{"id":"E2DswrkDR8xM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = CIFAR10(root='data/', download=True, train=True, transform=transforms.Lambda(PreProcessing)) # 50000 samples\n","test_data = CIFAR10(root='data/', download=True, train=False, transform=transforms.Lambda(PreProcessing)) # 10000 samples"],"metadata":{"id":"FIUvKLn4OU9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_size = 10000\n","train_size = len(dataset) - val_size\n","\n","train_data, val_data = random_split(dataset, [train_size, val_size])\n","print(f\"Training samples = {len(train_data)} \\nValidation samples = {len(val_data)} \\nTest samples = {len(test_data)}\")"],"metadata":{"id":"xzIt485BVIif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","  def __init__(self, dataset, noise_factor, device='cpu'):\n","    super().__init__()\n","    self.dataset = dataset\n","    self.nf = noise_factor\n","  def __len__(self):\n","    return len(self.dataset)\n","  def __getitem__(self, idx):\n","    x, _ = self.dataset[idx]\n","    x_noisy = x + self.nf*np.random.normal(loc=0.0, scale=1.0, size=x.shape)\n","    x_noisy = np.clip(x_noisy, 0., 1.).to(torch.float32)\n","    return (x.to(device), x_noisy.to(device))"],"metadata":{"id":"DFZ9nYycdpvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set niose factor for later\n","noise_factor = 0.1"],"metadata":{"id":"EvMiHgDFFoC1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [TO COMPLETE] SVD\n","\n","Similar to Principal component analysis (PCA), Singular Value Decomposition (SVD) is a standard linear dimensionality reduction method. They both linearly combine the features of the original high-dimensional dataset and project them into a lower-dimensional space, ideally retaing most of thier intrinsic properties.\n","\n","In this first part of the HW, we will focus our attention on SVD decomposition and its performances. Given a matrix $X$, the SVD decomposes it into the product of two unitary matrices, $V$ and $U$, and a rectangular diagonal matrix of singular values $S$:\n","\n","$$ X=V \\cdot S \\cdot U^T.$$\n","\n","The SVD is already implemented in PyTorch as `torch.linalg.svd`. In our case, the $X$ matrix will represent the training set, where each row is a sample (therefore the number of columns will be the number of input features). However, notice that the $X$ matrix has a huge number of rows (we have 50,000 input samples) and only 784 columns. If you are using the _Colab_ free plan, the quantity of available RAM may not be sufficient to compute the SVD of $X$. Therefore, to ease memory consumption and numerical stability, we resort to one property of the SVD and compute its equivalent version from the matrix $C= X^T \\cdot X$, that can be decomposed as:\n","\n","$$ C= U \\cdot S^2 \\cdot U^T$$\n","\n","Since we need just the matrix $U$ to compute the compressed version of our data, this trick turns out to be a quick and good solution."],"metadata":{"id":"ES5U0qECEQkC"}},{"cell_type":"code","source":["def svd_k(X, k):\n","  # k: sets the number of components to keep\n","\n","  # Compute the matrix C\n","  C = torch.matmul(X.T, X)\n","  # SVD decomposition\n","  U, s_sqr, U_T = torch.linalg.svd(C)\n","  # Limit the number columns of U to k\n","  U_k = U[:,:k]\n","  return U_k"],"metadata":{"id":"VE8R-LvjUy3q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we create the dataset ready for the SVD:"],"metadata":{"id":"nS15f2U4HXmB"}},{"cell_type":"code","source":["device = torch.device(\"cpu\") #for SVD\n","\n","x_train, x_train_noisy = next(iter(DataLoader(CustomDataset(train_data, noise_factor, device), batch_size=len(train_data))))\n","x_val, x_val_noisy = next(iter(DataLoader(CustomDataset(val_data, noise_factor, device), batch_size=len(val_data))))\n","x_test, x_test_noisy = next(iter(DataLoader(CustomDataset(test_data, noise_factor, device), batch_size=len(test_data))))\n","\n","x_train.shape, x_train_noisy.shape, x_val.shape, x_val_noisy.shape, x_test.shape, x_test_noisy.shape"],"metadata":{"id":"X2JAnY1OHVjs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pC6SJH7vzGYa"},"source":["Let's define the ENCODING_DIM, that will be the size of the compressed version of input data. And compute the compressed version of the training set and test set.\n"]},{"cell_type":"code","source":["ENCODING_DIM =  #[TO COMPLETE]\n","\n","U_k = svd_k(x_train, ENCODING_DIM)\n","\n","x_training_svd = torch.matmul(x_train, U_k)\n","x_test_svd = torch.matmul(x_test, U_k)"],"metadata":{"id":"q4r_FTp8WE7L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now reconstruct back the original input and check how much information was lost due to the compression. We do so by computing the mean squared error between the original input and the reconstruction, and by plotting the reconstructed images."],"metadata":{"id":"TGaM8AKOvX75"}},{"cell_type":"code","source":["x_training_reco = torch.matmul(x_training_svd, U_k.T)\n","x_test_reco = torch.matmul(x_test_svd, U_k.T)"],"metadata":{"id":"8WzR_M1bDTm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_train = ((x_train - x_training_reco)**2).mean()\n","accuracy_test = ((x_test - x_test_reco)**2).mean()\n","\n","print(\"Training mse: %.5f\" % ( accuracy_train))\n","print(\"Test mse: %.5f\" % ( accuracy_test))"],"metadata":{"id":"uxWUM5yTDwzO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_img(n, images_sets: list, title=\"\"):\n","  plt.figure(figsize=(20, 4))\n","  for i in range(n):\n","    for set_idx, images in enumerate(images_sets):\n","      ax = plt.subplot(len(images_sets), n, i + 1 + set_idx*n)\n","      plt.imshow(images[i].reshape(32, 32))\n","      plt.gray()\n","      ax.get_xaxis().set_visible(False)\n","      ax.get_yaxis().set_visible(False)\n","  plt.suptitle(title)\n","  plt.show()"],"metadata":{"id":"ogaa3ki9P0Tg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's see how well the input can be reconstructed by displaying a few of the input images and the corresponding reconstructions. Obviously, all these evaluations have to be done on the test set.\n","\n","The first row of images corresponds to input data, while the second one contains the reconstructions."],"metadata":{"id":"-R-JQw5Kvenf"}},{"cell_type":"code","source":["_ = plot_img(10, [x_test, x_test_reco], title=\"Original (top) vs reconstruction (bottom)\")"],"metadata":{"id":"U-BtLDiTP8-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**[TO COMPLETE]**: What happens by varying the ENCODING_DIM?\n"," Test and discuss the results in a cell below."],"metadata":{"id":"uMYVkoYtxSpi"}},{"cell_type":"markdown","source":["`%STARTEXT`"],"metadata":{"id":"msPWQ4bGsdjI"}},{"cell_type":"markdown","source":["**ANSWER**:"],"metadata":{"id":"9yrqnXwNhrnx"}},{"cell_type":"markdown","source":["`%ENDEXT`"],"metadata":{"id":"13MDJ3Kvsee_"}},{"cell_type":"markdown","source":["# [TO COMPLETE] Shallow Linear Autoencoder"],"metadata":{"id":"2Ju0nFYvESmL"}},{"cell_type":"markdown","source":["Let's define a model that consists of a single fully-connected neural layer. The hidden layer and the output layer act as the encoder and the decoder, respectively. First, we define the `DataLoader` to train the model."],"metadata":{"id":"rTUY-uYyipbA"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch_size = 512\n","noise_factor = 0.1 # adjust the noise level here.\n","\n","dataloader_train_AE = DataLoader(CustomDataset(train_data, noise_factor, device), batch_size = batch_size)\n","dataloader_val_AE = DataLoader(CustomDataset(val_data, noise_factor, device), batch_size = batch_size)\n","dataloader_test_AE = DataLoader(CustomDataset(test_data, noise_factor, device), batch_size = batch_size)"],"metadata":{"id":"5c7H76UBMcXn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then, we build our shallow Autoencoder. Here's a breakdown of the code to help you grasp how it works:\n","\n","1. The `__init__` method is the initialization function for the Auto_Encoder class. It takes four parameters: `input_dim` (dimensionality of the input data), `enc_layers` (a list specifying the sizes of the encoder layers), `dec_layers` (a list specifying the sizes of the decoder layers), and `act_fun` (the activation function to be used).\n","\n","2. The `nn.ModuleList()` is used to create empty lists E_layers and D_layers to store the encoder and decoder layers, respectively.\n","\n","3. The `for loop `iterates over the `enc_layers` list to create the encoder layers. For the first layer, it creates a linear layer (`nn.Linear`) mapping from the input dimension to the size of the first encoder layer. For subsequent layers, it creates linear layers mapping between consecutive encoder layer sizes. The created layers are appended to the `self.E_layers` list.\n","\n","4. The code then checks if the `dec_layers` list is empty. If it is empty, it creates a single linear layer mapping from the last encoder layer size to the input dimension (remember: the goal of the AE is to reconstruct the input). Otherwise, it iterates over the `dec_layers` list to create the decoder layers, similar to how the encoder layers were created. The last decoder layer is always mapped to the input dimension.\n","\n","5. The `_init_weights` method is a helper function that initializes the weights of the linear layers. It is applied to all modules (layers) of the Auto_Encoder instance.\n","\n","6. The `forward` method defines the forward pass of the Autoencoder."],"metadata":{"id":"IZN87W07KRgV"}},{"cell_type":"code","source":["class Auto_Encoder(nn.Module):\n","  \n","  def __init__(self, input_dim, enc_layers, dec_layers, act_fun):\n","    super().__init__()\n","\n","    self.E_layers = nn.ModuleList()\n","    self.D_layers = nn.ModuleList()\n","    self.act_fun = act_fun\n","    activation_functions = {'linear': transforms.Lambda(lambda x: x),\n","                            'sigmoid': F.sigmoid,\n","                            'relu': F.relu,\n","                            'tanh': F.tanh,\n","                            'leaky_relu': F.leaky_relu}\n","    assert self.act_fun in activation_functions, f'Activation Functions: {activation_functions.keys()}'\n","    self.af = activation_functions[self.act_fun]\n","\n","    for layer_idx in range(len(enc_layers)):\n","      if layer_idx == 0:  # first layer, from input to enc\n","        self.E_layers = self.E_layers.append(nn.Linear(input_dim, enc_layers[layer_idx]))\n","      else:  # hidden layers, depending on the input\n","        self.E_layers = self.E_layers.append(nn.Linear(enc_layers[layer_idx-1], enc_layers[layer_idx]))\n","\n","    if len(dec_layers) == 0:\n","      self.D_layers = self.D_layers.append(nn.Linear(enc_layers[-1], input_dim))\n","    else:\n","      for layer_idx in range(len(dec_layers)):\n","        if layer_idx == 0:  # first layer, from enc to dec\n","          self.D_layers = self.D_layers.append(nn.Linear(enc_layers[-1], dec_layers[layer_idx]))\n","        else:  # hidden layers, depending on the input\n","          self.D_layers = self.D_layers.append(nn.Linear(dec_layers[layer_idx-1], dec_layers[layer_idx]))\n","    \n","      self.D_layers = self.D_layers.append(nn.Linear(dec_layers[-1], input_dim)) # final output layer\n","    \n","    self.apply(self._init_weights)\n","    \n","  def _init_weights(self, module):\n","    if isinstance(module, nn.Linear):\n","        module.weight.data.normal_(mean=0.0, std=.1)\n","        if module.bias is not None:\n","            module.bias.data.zero_()\n","  \n","  def forward(self, x):\n","    for layer in self.E_layers:\n","      x = self.af(layer(x))\n","    for layer in self.D_layers[:-1]:\n","      x = self.af(layer(x))\n","    if self.act_fun == 'linear':\n","      return self.D_layers[-1](x)\n","    else:\n","      return F.sigmoid(self.D_layers[-1](x)) #last act func is always sigmoid"],"metadata":{"id":"PH7LRILHEiCG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[TO COMPLETE]** Check the results and compare them with the ones obtained with the SVD. In the cell at the end of this section (after the result of the linear autoencoder), give an explanation of the relation between the results obtained  by the shallow linear autoencoder and the ones obtained by the SVD decomposition. \n","\n","Try also to be aquainted with the usual PyTorch training and evaluation routines. In the following part of the HW, the more training epochs the better the resutls, but it will also take longer. Feel free to change the `epochs` variable, just be consistent to make fair comparisons."],"metadata":{"id":"LWxeFLTZjAlh"}},{"cell_type":"code","source":["IN_DIM = x_train.shape[-1]\n","ENC_LAYERS = [256] \n","DEC_LAYERS = [] \n","ACT_FUN = 'linear'\n","lr = 0.005\n","epochs = 30 # Feel free to lower this to speed up the training times. Nevertheless, do not go below 25 epochs.\n","\n","Shallow_AE = Auto_Encoder(IN_DIM, ENC_LAYERS, DEC_LAYERS, ACT_FUN).to(device)\n","summary(Shallow_AE, input_size=(batch_size, IN_DIM))"],"metadata":{"id":"m9oIrhGWQhRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(Shallow_AE.parameters(), lr=lr)"],"metadata":{"id":"wvpIkU0lXF6e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, optimizer, dataloader_train, dataloader_val, epochs, denoising=False):\n","  loss_train, loss_val = [], []\n","  for epoch in range(epochs):\n","\n","    model.train()\n","    total_count_train, n_train_batches, total_loss_train = 0, 0, 0\n","    for idx, (x, x_noisy) in enumerate(dataloader_train):\n","      optimizer.zero_grad()\n","      if denoising:\n","        x_rec = model(x_noisy)\n","      else:\n","        x_rec = model(x)\n","      loss = criterion(x_rec, x)\n","      total_loss_train += loss\n","      loss.backward()\n","      optimizer.step()\n","\n","      total_count_train += x.size(0)\n","      n_train_batches += 1\n","\n","    avg_loss_train = total_loss_train/n_train_batches\n","    loss_train.append(avg_loss_train.item())\n","    \n","    total_count_val, n_val_batches, total_loss_val = 0, 0, 0\n","    with torch.no_grad():\n","        model.eval()\n","        for idx, (x, x_noisy) in enumerate(dataloader_val):\n","            if denoising:\n","              x_rec = model(x_noisy)\n","            else:\n","              x_rec = model(x)\n","\n","            loss = criterion(x_rec, x)\n","            total_loss_val += loss\n","            total_count_val += x.size(0)\n","            n_val_batches += 1\n","\n","    avg_loss_val = total_loss_val/n_val_batches\n","    loss_val.append(avg_loss_val.item())\n","    if epoch % 1 == 0:\n","      print(f\"epoch: {epoch+1} -> Loss: {avg_loss_train:.8f}\",end=\" ---------------- \")\n","      print(f\"Val_Acc: Val_Loss: {avg_loss_val:.8f}\")\n","  return loss_train, loss_val"],"metadata":{"id":"Wu05jc0KOkFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = timer()\n","loss_train, loss_val = train(Shallow_AE, optimizer, dataloader_train_AE,\n","                             dataloader_val_AE, epochs)\n","end = timer()\n","print(f\"Training time in second: {(end - start)}\")"],"metadata":{"id":"5UOpar56OkHz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_learning_acc_and_loss(loss_tr, loss_val):\n","    info = {'loss_training':loss_tr, 'loss_validation':loss_val}\n","    df = pd.DataFrame(info)\n","    df.plot(figsize=(10, 8), subplots=[('loss_training','loss_validation')], grid=True)\n","    plt.xlabel(\"Epochs\")\n","    plt.show()"],"metadata":{"id":"kfSXTwv_QEOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_learning_acc_and_loss(loss_train, loss_val)"],"metadata":{"id":"rDuFhYdbRgVo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(model, dataloader_test=dataloader_test_AE, denoising=False): #dataloader_test_AE not train\n","  model.eval()\n","  total_count_test, n_batches_test, loss = 0, 0, 0\n","  for idx, (x, x_noisy) in enumerate(dataloader_test):\n","      if denoising:\n","        x_rec = model(x_noisy)\n","      else:\n","        x_rec = model(x)\n","      loss += criterion(x_rec, x)\n","      total_count_test += x.size(0)\n","      n_batches_test += 1\n","  loss_test = loss/n_batches_test\n","  print(f\"Test Loss: {loss_test:.8f}\")"],"metadata":{"id":"mGhQrMk4RlOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(Shallow_AE)"],"metadata":{"id":"mSacOR4ISH1E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def apply_on_test(model, device, denoising=False):\n","  if denoising:\n","    x = x_test_noisy.to(device)\n","  else:\n","    x = x_test.to(device)\n","  for layer in model.E_layers:\n","      x = model.af(layer(x))\n","  encoded_imgs = x\n","\n","\n","  y = encoded_imgs\n","  for layer in model.D_layers[:-1]:\n","      y = model.af(layer(y))\n","  if model.act_fun == 'linear':\n","    decoded_imgs = model.D_layers[-1](y)\n","  else:\n","    decoded_imgs = F.sigmoid(model.D_layers[-1](y))\n","\n","  return (encoded_imgs.to(\"cpu\"), decoded_imgs.to(\"cpu\"))"],"metadata":{"id":"w29Z0JgIUeYA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_imgs, decoded_imgs = apply_on_test(model=Shallow_AE, device=device)"],"metadata":{"id":"IPUyQzpZTI5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_img(10, [x_test, decoded_imgs], title=\"Original (top) vs reconstruction (bottom)\")"],"metadata":{"id":"6lZZB1eBS4Le"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comment the results obtained with the shallow linear autoencoder in relation to the ones obtained by the SVD decomposition. Are they different or similar? Why do you think they are so? (hint: consider the theoretical relationship between SVD and a shallow linear autoencoder.)"],"metadata":{"id":"tsu-nOh4jKrv"}},{"cell_type":"markdown","source":["`%STARTEXT`"],"metadata":{"id":"sQ8QG7ImstcU"}},{"cell_type":"markdown","source":["**ANSWER**:"],"metadata":{"id":"wNMfqg-sjm0n"}},{"cell_type":"markdown","source":["`%ENDTEXT`"],"metadata":{"id":"y1oySHJrsujv"}},{"cell_type":"markdown","source":["# [TO COMPLETE] Shallow non-linear Autoencoder"],"metadata":{"id":"nWbk3trxXR0-"}},{"cell_type":"markdown","source":["**[TO COMPLETE]** Replicate the code of the previous exercise but in this case, instead of using linear activation functions use non-linear ones. Choose the most appropriate non-linear function, and motivate your choice in the last cell of this section. Discuss the results you obtained in relation to those obtained with the Shallow Linear Autoencoder."],"metadata":{"id":"VmJbfvrRkEs8"}},{"cell_type":"markdown","source":["`%STARTCODE`"],"metadata":{"id":"7DoMVdiys7zE"}},{"cell_type":"code","source":["# [TO COMPLETE]\n","# define model and training hyperparameters\n","# END\n","\n","Shallow_non_AE = Auto_Encoder(IN_DIM, ENC_LAYERS, DEC_LAYERS, ACT_FUN).to(device)\n","summary(Shallow_non_AE, input_size=(batch_size, IN_DIM))"],"metadata":{"id":"B_hQPabdTxZn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(Shallow_non_AE.parameters(), lr=lr)"],"metadata":{"id":"pbHvD78-XZSU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = timer()\n","loss_train, loss_val = train(Shallow_non_AE, optimizer, dataloader_train_AE,\n","                             dataloader_val_AE, epochs)\n","end = timer()\n","print(f\"Training time in second: {(end - start)}\")"],"metadata":{"id":"E2xd_OLiXZUl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_learning_acc_and_loss(loss_train, loss_val)"],"metadata":{"id":"RSApmRxwX0Yq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(Shallow_non_AE)"],"metadata":{"id":"5_4MvZj1X0bM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_imgs, decoded_imgs = apply_on_test(model=Shallow_non_AE, device=device)\n","\n","plot_img(10, [x_test, decoded_imgs], title=\"Original (top) vs reconstruction (bottom)\")"],"metadata":{"id":"7WY4fDw2X0dn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`%ENDCODE`"],"metadata":{"id":"dW_yjDFhs-YK"}},{"cell_type":"markdown","source":["Discuss the results you obtained with the activation functions you have tested and also motivate your choice. Compare your results to the ones obtained with the Shallow Linear Autoencoder."],"metadata":{"id":"GWwu26qEk2qO"}},{"cell_type":"markdown","source":["`%STARTEXT`"],"metadata":{"id":"Equ4t8zktCoJ"}},{"cell_type":"markdown","source":["**ANSWER**:"],"metadata":{"id":"cPrYWj6vlCpW"}},{"cell_type":"markdown","source":["`%ENDTEXT`"],"metadata":{"id":"wT9m7cm-tFMv"}},{"cell_type":"markdown","source":["# [TO COMPLETE] Deep Autoencoder"],"metadata":{"id":"zkqz4b83YWlu"}},{"cell_type":"markdown","source":["**[TO COMPLETE]**: Define a deep version of the Autoeancoder defined above. The autoencoder has to **use at least $5$ layers**. The model will use ùëõ layers for encoding, and $n-1$ for decoding. The layers sizes of the encoding part decrease at each layer (e.g. `IN_DIM` ‚Üí $k$ ‚Üí $k/2$, where $k/2$ is the arbitrarly chosen encoding dim). The decoding part layers dimensions progression turns out to be mirrored (i.e., $k$ ‚Üí `IN_DIM`, the resulting overall structure recalls an hourglass!). Try different hyperparameters configurations and write a short report of your experiments below. Leave the best execution in the code cells."],"metadata":{"id":"YVMTdx3plo5q"}},{"cell_type":"markdown","source":["`%STARTCODE`"],"metadata":{"id":"3i3R1uxJtJV1"}},{"cell_type":"code","source":["# [TO COMPLETE]\n","# define model and training hyperparameters\n","# END\n","\n","DEEP_non_AE = Auto_Encoder(IN_DIM, ENC_LAYERS, DEC_LAYERS, ACT_FUN).to(device)\n","summary(DEEP_non_AE, input_size=(batch_size, IN_DIM))"],"metadata":{"id":"3vwnMWf5YbUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(DEEP_non_AE.parameters(), lr=lr)"],"metadata":{"id":"PIdxBkiNY_bI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = timer()\n","loss_train, loss_val = train(DEEP_non_AE, optimizer, dataloader_train_AE,\n","                             dataloader_val_AE, epochs)\n","end = timer()\n","print(f\"Training time in second: {(end - start)}\")"],"metadata":{"id":"HXzsFPirY_dl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_learning_acc_and_loss(loss_train, loss_val)"],"metadata":{"id":"kt33vdt3ZDCk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(DEEP_non_AE)"],"metadata":{"id":"ji4KMbaUZDFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_imgs, decoded_imgs = apply_on_test(model=DEEP_non_AE, device=device)\n","\n","plot_img(10, [x_test, decoded_imgs], title=\"Original (top) vs reconstruction (bottom)\")"],"metadata":{"id":"Hy5NgsixZJ1V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`%ENDCODE`"],"metadata":{"id":"PqA66dYntKja"}},{"cell_type":"markdown","source":["Write a short report of the results you obtained trying different hyperparameters configurations."],"metadata":{"id":"gc3ebcbeowFH"}},{"cell_type":"markdown","source":["`%STARTEXT`"],"metadata":{"id":"6t5BvlFWtN_w"}},{"cell_type":"markdown","source":["**ANSWER**:"],"metadata":{"id":"MMo6Auzoo3i7"}},{"cell_type":"markdown","source":["`%ENDTEXT`"],"metadata":{"id":"yiOdxG8mtPp4"}},{"cell_type":"markdown","source":["# [TO COMPLETE] Shallow Denoising Autoencoder"],"metadata":{"id":"xGU1AiwnZdqF"}},{"cell_type":"markdown","source":["**[TO COMPLETE]** Let's now use a shallow autoencoder to denoise the input data. We have defined a Dataloader able to return a noisy version of the input data. You can activate this capability by passing the parameter `denoising=True` to the `train` function.\n","\n","Run some experiments with different hyperparameters values. You can also re-create the dataloaders at the beginning of the notebook and test what happens if you increase the noise level above $0.1$. Write a short report of your findings below."],"metadata":{"id":"NCfxiXqSmmx-"}},{"cell_type":"code","source":["plot_img(10, [x_test, x_test_noisy])"],"metadata":{"id":"gGqHSjirKXpM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`%STARTCODE`"],"metadata":{"id":"LUmGcAnitTfb"}},{"cell_type":"code","source":["# [TO COMPLETE]\n","# define model and training hyperparameters\n","# END\n","\n","SHALLOW_denoising_AE = Auto_Encoder(IN_DIM, ENC_LAYERS, DEC_LAYERS, ACT_FUN).to(device)\n","summary(SHALLOW_denoising_AE, input_size=(batch_size, IN_DIM))"],"metadata":{"id":"2ySFXVG-ZgD5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(SHALLOW_denoising_AE.parameters(), lr=lr)"],"metadata":{"id":"VFrmB0n8ZgGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = timer()\n","\n","# [TO COMPLETE]\n","# call the training function on noisy data\n","loss_train, loss_val = train(SHALLOW_denoising_AE, optimizer, dataloader_train_AE,\n","                             dataloader_val_AE, epochs, denoising= #[TO COMPLETE])\n","\n","end = timer()\n","print(f\"Training time in second: {round(end - start)}\")"],"metadata":{"id":"yTJR5CQuZgI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_learning_acc_and_loss(loss_train, loss_val)"],"metadata":{"id":"izlYlANsZ8Wv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(SHALLOW_denoising_AE, denoising=True)"],"metadata":{"id":"LNeHPo6DZ8ZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_imgs, decoded_imgs = apply_on_test(model=SHALLOW_denoising_AE, device=device, denoising=True)\n","\n","plot_img(10, [x_test_noisy, x_test, decoded_imgs], title=\"Noisy, Original vs Reconstruction\")"],"metadata":{"id":"aEsuYF7_aFGj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`%ENDCODE`"],"metadata":{"id":"aSdi80NrtcJY"}},{"cell_type":"markdown","source":["How strong is the impact of the noise factor on the model's denoising capability? What hyperparameter configuration worked for the noise levels you have tried?"],"metadata":{"id":"n9c6ZLNXqReT"}},{"cell_type":"markdown","source":["`%STARTEXT`"],"metadata":{"id":"071G7w38te84"}},{"cell_type":"markdown","source":["**ANSWER**:"],"metadata":{"id":"4gzjappNqjqB"}},{"cell_type":"markdown","source":["`%ENDTEXT`"],"metadata":{"id":"6Eui6ItWthrl"}}]}