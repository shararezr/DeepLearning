{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Learning Homework 6: *Variational Autoencoders***\n",
        "### MSc Computer Science, Data Science, Cybersecurity Computer Engeneering @UniPD\n",
        "### 2nd semester - 6 ECTS\n",
        "### Prof. Alessandro Sperduti, Prof. NicolÃ² Navarin & Dr. Luca Pasa\n",
        "---\n",
        "\n",
        "In this homework, we will explore how to develop a Variational Autoencoder (VAE). We will define a Variational Autoencoder starting from basic PyTorch components. Then, we will define a training loop which includes the two losses used to train VAEs, namely the reconstruction loss and the KL-divergence loss.\n",
        "Using this training loop, we will fit the model on the MNIST dataset choosing  appropriate hyperparameters. Finally, we will and explore and analyze the latent encodings learned by the model thanks to some visualization techniques.\n",
        "\n",
        "**NOTE**: in order to run this notebook without problems, please connect to a *GPU runtime*. You can do so by clicking on the RAM / Disk icon in the upper right part of the notebook, then on *Change runtime type* at the bottom of the page, and then select the GPU hardware accelerator.\n"
      ],
      "metadata": {
        "id": "lcALBTR4yoXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Requirements"
      ],
      "metadata": {
        "id": "idIcYuYAXYyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install datasets skorch pandas~=1.5 torch~=1.13 torchinfo torchdata~=0.5 torchtext~=0.14 torchvision~=0.14 torchaudio~=0.13 "
      ],
      "metadata": {
        "id": "635YXDfNXc_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "NeD2_4dPXhcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchinfo import summary\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "OuWiqKXSXitU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "G7pag0cXY-Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loading and Preprocessing\n",
        "\n",
        "We load the MNIST dataset. The dataset contains 60,000 training grayscale images and 10,000 testing image of handwritten digits. We chose to use a 128-dimensional batch in order to make the training process reasonably fast -- you should thus leave this value unchanged."
      ],
      "metadata": {
        "id": "XMyO2wSeXlDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Trns = transforms.ToTensor()\n",
        "def preprocess(img):\n",
        "  img = Trns(img)\n",
        "  H, W = img.shape[1:]\n",
        "  img = img.reshape((H*W, ))\n",
        "  return img\n",
        "\n",
        "MNIST = datasets.MNIST(root='./data', train=True, download=True, transform=preprocess)"
      ],
      "metadata": {
        "id": "lYrfto9nA3BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "dataloader = DataLoader(MNIST, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "7_RpV_IYA3GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us see one of the digits:"
      ],
      "metadata": {
        "id": "s1NRGIDIm_iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(dataloader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "plt.imshow(images[0].reshape(28,28), cmap='gray')\n",
        "plt.title(f\"Label: {labels[0]+1}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZZw8hx7jmeL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[TO COMPLETE] VAE Architecture\n",
        "\n",
        "###Exercise 6.1: Variational Autoencoder: reparameterization trick\n",
        "To implement a VAE we have to define two main parts: the _Encoder_ and the _Decoder_.\n",
        "Let's start by the Encoder, that computes an encoding of the input from which it computes the mean and the average of the sample distribution.\n",
        "Once we have these two statistics, we have to implement the sampling phase. Keras does not provide any predefined method to perform this operation, therefore we have to define it. With the aim to be consistent with the layer-composition paradigm used by Keras in defining a model, we define a Sampling layer as a new layer.\n",
        "\n",
        "In our case, the Sampling layer has in input the tuple made of the mean and the log-variance, and it has to compute the sample $z$ from them by exploiting the reparameterization trick:\n",
        "$$\n",
        "z=z_{mean} + exp(z_{var}/2) * \\epsilon\n",
        "$$\n",
        "The reparameterization trick is used in VAE because it actually helps in the backpropagation process. Specifically, $\\epsilon \\sim \\mathcal{N}(0,1)$ actually reparameterizes our VAE network. This allows the mean and log-variance vectors to still remain as the learnable parameters of the network while  maintaining the stochasticity of the entire system via epsilon.\n",
        "\n",
        "\n",
        "As usual, we will provide the structure of the implementation of the VAE in PyTorch. The Encoder and Decoder are embodied by the `E_layers` and `D_layers` respectively.<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "**[TO COMPLETE]** Complete the code of the VAE model defining:\n",
        "\n",
        "1. the dense layers that model `z_mean` and `z_var`\n",
        "2. the sampling function that implements the reparametrization trick\n",
        "3. the reparameterization trick in the forward function.\n",
        "\n",
        "*Hint*: to generate random values from a normal distribution you can use the PyTorch [torch.randn](https://pytorch.org/docs/stable/generated/torch.randn.html) function, and make sure the output shape is the proper one.\n"
      ],
      "metadata": {
        "id": "lucRYd-JXprr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%STARTCODE%`"
      ],
      "metadata": {
        "id": "1zuPBz7D3D0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self, input_dim, ENC_LAYERS, latent_dim, DEC_LAYERS, act_fun, last_layer_act_fun):\n",
        "    super().__init__()\n",
        "  \n",
        "    self.E_layers = nn.ModuleList()\n",
        "    self.D_layers = nn.ModuleList()\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "    activation_functions = {'linear':transforms.Lambda(lambda x: x), 'sigmoid':F.sigmoid, 'relu':F.relu, 'tanh': F.tanh, 'leaky_relu': F.leaky_relu}\n",
        "    assert act_fun in activation_functions, f'Activation Functions: {activation_functions.keys()}'\n",
        "    self.af = activation_functions[act_fun]\n",
        "    self.last_af = activation_functions[last_layer_act_fun]\n",
        "\n",
        "    for layer_idx in range(len(ENC_LAYERS)):\n",
        "      if layer_idx == 0:  # first layer, from input to enc\n",
        "        self.E_layers = self.E_layers.append(nn.Linear(input_dim, ENC_LAYERS[layer_idx]))\n",
        "      else:  # hidden layers, depending on the input\n",
        "        self.E_layers = self.E_layers.append(nn.Linear(ENC_LAYERS[layer_idx-1], ENC_LAYERS[layer_idx]))\n",
        "    \n",
        "    ### TO COMPLETE\n",
        "    # 1. define the dense layers that model z_mean and z_var\n",
        "    self.linear_mean = # [your code here]\n",
        "    self.linear_var = # [your code here]\n",
        "    ###\n",
        "\n",
        "    if len(DEC_LAYERS) == 0:\n",
        "      self.D_layers = self.D_layers.append(nn.Linear(ENC_LAYERS[-1], input_dim))\n",
        "    else:\n",
        "      for layer_idx in range(len(DEC_LAYERS)):\n",
        "        if layer_idx == 0:  # first layer, from enc to dec\n",
        "          self.D_layers = self.D_layers.append(nn.Linear(latent_dim, DEC_LAYERS[layer_idx]))\n",
        "        else:  # hidden layers, depending on the input\n",
        "          self.D_layers = self.D_layers.append(nn.Linear(DEC_LAYERS[layer_idx-1], DEC_LAYERS[layer_idx]))\n",
        "\n",
        "    self.final_fc = nn.Linear(DEC_LAYERS[-1], input_dim)\n",
        "  \n",
        "  def sampling(self, z_mean, z_var):\n",
        "    ### TO COMPLETE\n",
        "    # 2. write the sampling function that implements the reparametrization trick\n",
        "    # [your code here]\n",
        "    return z\n",
        "    ###\n",
        "\n",
        "  def encode(self, x):\n",
        "    \"\"\"This function implmements the encoder part of our VAE.\n",
        "    It will also be useful to explore the latent space learned after training!\n",
        "    \"\"\"\n",
        "    for layer in self.E_layers:\n",
        "      x = self.af(layer(x))\n",
        "    return x\n",
        "\n",
        "  def decode(self, z):\n",
        "    \"\"\"This function implmements the decoder part of our VAE.\n",
        "    It will also be useful to explore the latent space learned after training!\n",
        "    \"\"\"\n",
        "    for layer in self.D_layers:\n",
        "      z = self.af(layer(z))\n",
        "    \n",
        "    out = self.final_fc(z)\n",
        "\n",
        "    return self.last_af(out)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.encode(x)\n",
        "\n",
        "    ### TO COMPLETE\n",
        "    # 3. use the linear layers and the sampling function you defined above\n",
        "    # to compute the sample z\n",
        "    # [your code here]\n",
        "    self.z = # [your code here]\n",
        "    ###\n",
        "\n",
        "    return self.decode(self.z)"
      ],
      "metadata": {
        "id": "vWO3tYDVA3Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%ENDCODE%`"
      ],
      "metadata": {
        "id": "Ft6DjC1Q3JLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#[TO COMPLETE] Loss Functions\n",
        "\n",
        "Now we have defined the VAE but, since it is a generative model, we have to define an ad-hoc training phase. Specifically, we have to manage the two losses used for this model. Indeed the parameters of a VAE are trained via two loss functions: a reconstruction loss, that forces the decoded samples to match the initial inputs, and a regularization loss that helps to learn  a well-formed latent space, and to reduce overfitting. The regularization loss is handled with the _Kullback-Liebler Divergence_. On the other hand, for the reconstruction loss we will use the _binary cross-entropy_ to compare each feature of a data point to the value in the reconstructed output.\n",
        "\n",
        "**[TO COMPLETE]**: Implement the reconstruction loss and the KL-divergence.\n",
        "\n",
        "*Disclaimer*: To implement the reconstruction loss you can use function or classes already available in PyTorch, while you must implement the KL-divergence from scratch, explointing the attributes in the `VAE` class."
      ],
      "metadata": {
        "id": "Z2NT_-yGXto7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%STARTCODE%`"
      ],
      "metadata": {
        "id": "6HlmRfKN3WEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's define the reconstruction loss...\n",
        "REC_LOSS = ### TO COMPLETE \n",
        "\n",
        "#..and the Kullback-Liebler Divergence\n",
        "def KL_LOSS(model):\n",
        "  ### TO COMPLETE\n",
        "  \n",
        "  return loss\n",
        "  ###"
      ],
      "metadata": {
        "id": "CV6kikHtKTN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%ENDCODE%`"
      ],
      "metadata": {
        "id": "rgw_7Mrg3WWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[TO COMPLETE] Training\n",
        "\n",
        "We define the training loop. Notice how we set a $\\beta$ parameter to weight the combination of the two losses. "
      ],
      "metadata": {
        "id": "kOMBUkZqXvpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, dataloader, epochs, Beta=1e-3):\n",
        "  loss_train_rec, loss_train_kl, loss_train = [], [], []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    n_train_batches, rec_train, kl_train, total_loss_train = 0, 0, 0, 0\n",
        "\n",
        "    for idx, (img, _) in enumerate(dataloader):\n",
        "      # reset the gradient for all parameters\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # move the input to currently used device\n",
        "      img = img.to(device)\n",
        "\n",
        "      # run the model\n",
        "      rec_img = model(img)\n",
        "      \n",
        "      # compute the loss for this sample\n",
        "      rec_loss = REC_LOSS(rec_img, img)\n",
        "      kl_loss = KL_LOSS(model)\n",
        "      total_loss = rec_loss + Beta * kl_loss\n",
        "\n",
        "      # accumulate the loss for this epoch\n",
        "      total_loss_train += total_loss\n",
        "      rec_train += rec_loss\n",
        "      kl_train += kl_loss\n",
        "\n",
        "      # compute the gradients and update weights\n",
        "      total_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      n_train_batches += 1\n",
        "\n",
        "    # compute losses for this epoch\n",
        "    avg_loss_train = total_loss_train/n_train_batches\n",
        "    avg_rec_loss_train = rec_train/n_train_batches\n",
        "    avg_kl_loss_train = kl_train/n_train_batches\n",
        "\n",
        "    # store losses\n",
        "    loss_train.append(avg_loss_train.item())\n",
        "    loss_train_rec.append(avg_rec_loss_train.item())\n",
        "    loss_train_kl.append(avg_kl_loss_train.item())\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "      print(f\"epoch: {epoch+1} -> Loss: {avg_loss_train:.8f}\", end=' ----- ')\n",
        "      print(f\"Rec Loss: {avg_rec_loss_train:.8f}\", end=' ----- ')\n",
        "      print(f\"Effective KL Loss: {Beta * avg_kl_loss_train:.8f}\")\n",
        "\n",
        "  return loss_train, loss_train_rec, loss_train_kl"
      ],
      "metadata": {
        "id": "3_tiNdTAJD_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(loss_train, loss_rec, loss_kl):\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.grid(True)\n",
        "  plt.title(\"Reconstruction Loss\")\n",
        "  plt.plot(loss_rec)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.title(\"KL Loss\")\n",
        "  plt.grid(True)\n",
        "  plt.plot(loss_kl)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "k_ZoGz6YUcnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[TO COMPLETE]:** \n",
        "Your task is to make the VAE working well and learn the digits'representstions. Define the hyperparameters for the encoder and decoder layers. Explain choice for what concerns the number of layers, the layers sizes, and the activation functions in the cells below.\n",
        "\n",
        "_Hint:_ Note that we should define the `latent_dim` (that is the dimension of $z$) to $2$. This choice is made to make possible to represent the results graphically.\n",
        "Pay attention to the relation between the decoding and encoding layers."
      ],
      "metadata": {
        "id": "Ya9ovXfG0S22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%STARTCODE%`"
      ],
      "metadata": {
        "id": "XNH8LhMQ3df2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TO COMPLETE\n",
        "# ENC_LAYERS and DEC_LAYERS should be lists describing the number and size of \n",
        "# encoding / decoding layers\n",
        "input_dim = ###TO COMPLETE\n",
        "ENC_LAYERS =  [] ###TO COMPLETE\n",
        "latent_dim = 2\n",
        "DEC_LAYERS =  [] ###TO COMPLETE\n",
        "act_fun =  ###TO COMPLETE\n",
        "last_layer_act_fun =  ###TO COMPLETE\n",
        "###\n",
        "\n",
        "vae = VAE(input_dim, ENC_LAYERS, latent_dim, DEC_LAYERS, act_fun, last_layer_act_fun).to(device)\n",
        "summary(vae, input_size=(input_dim, ))"
      ],
      "metadata": {
        "id": "btoIAhwSK-zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train out model:"
      ],
      "metadata": {
        "id": "wk_K4hk7y8q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "epochs = 30\n",
        "\n",
        "optimizer = torch.optim.Adam(vae.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "GCPIy9yHEHKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = timer()\n",
        "loss_train, loss_rec, loss_kl = train(vae, optimizer, dataloader, epochs)\n",
        "end = timer()\n",
        "print(f\"Training time in second: {(end - start)}\")"
      ],
      "metadata": {
        "id": "pQgGD7PWLwSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(loss_train, loss_rec, loss_kl)"
      ],
      "metadata": {
        "id": "RR_IeW77TTT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%ENDCODE%`"
      ],
      "metadata": {
        "id": "FMgRbY553iwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%STARTEXT`"
      ],
      "metadata": {
        "id": "nlQn82rm1dkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[TO COMPLETE]** Comment on your choice of number of layers, the layers sizes, and the activation functions.\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "OP1pLtok1Scn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%ENDTEXT`"
      ],
      "metadata": {
        "id": "qlpd5SGl1eOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[TO COMPLETE] Generation\n",
        "\n",
        "The best part about generative models is that they can generate new data (ChatGPT is pretty good at it ðŸ™ƒ). We can therefore plot an example of the data generation by using the decoder part. Since we used a 2D latent space let's generate sevral possibile 2D $\\hat{z}$ samples and pass them to our decoder. With the $scale$ parameter we can define the interval from where the entries of $\\hat{z}$ are chosen, and with parameter $n$ it is possibile to define how many samples are generated.  "
      ],
      "metadata": {
        "id": "Oi0Py2sXX0Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_latent(decoder, scale=2.0, n = 30):\n",
        "     \n",
        "    digit_size = 28\n",
        "    figsize = 15\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "    # here we systematically generate 2D samples of z_hat...\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            # ...we cast and reshape the samples\n",
        "            z_sample = torch.tensor([[xi, yi]], dtype=torch.float32).to(device)\n",
        "            # ...and then we pass them to the decoder, \n",
        "            # without keeping track of the gradient\n",
        "            with torch.no_grad():\n",
        "              x_decoded = vae.decode(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size).to('cpu')\n",
        "            figure[\n",
        "                i * digit_size : (i + 1) * digit_size,\n",
        "                j * digit_size : (j + 1) * digit_size,\n",
        "            ] = digit\n",
        "\n",
        "    # Finally we plot the generated data\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_latent(decoder, 2.0, 30) "
      ],
      "metadata": {
        "id": "NfdC0dQoUzI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final result is quite impressive, considering that all these digits are artificial and they not belong to any dataset!\n",
        "Let's finally check how the various digits have been represented in the latent space by the VAE."
      ],
      "metadata": {
        "id": "3tH6QvYM0EgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = next(iter(DataLoader(MNIST, batch_size=len(MNIST))))"
      ],
      "metadata": {
        "id": "bfqf02zLo4UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_label_clusters(data, labels):\n",
        "    with torch.no_grad():\n",
        "      # let's compute the encodings \n",
        "      encoding = vae.encode(data.to(device))\n",
        "      # and then the mean used in the reparameterization trick\n",
        "      z_mean = vae.linear_mean(encoding).to('cpu')\n",
        "    \n",
        "    # Let's plot the latent space\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z_mean[0]\")\n",
        "    plt.ylabel(\"z_mean[1]\")\n",
        "    plt.show()\n",
        "\n",
        "plot_label_clusters(x_train, y_train)"
      ],
      "metadata": {
        "id": "vd8n-bVqoMZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[TO COMPLETE]** Explore how the hyper-parameters of the VAE (number of layers, layer sizes, etc.) influence the final result. Discuss the obtained plots, and different hyperparameters you have tried. Insert your discussion below:"
      ],
      "metadata": {
        "id": "Iallop1k388Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%STARTEXT`"
      ],
      "metadata": {
        "id": "URtjTNNA2MWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: "
      ],
      "metadata": {
        "id": "wS4V4EMs1uhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%ENDTEXT`"
      ],
      "metadata": {
        "id": "oyFUFjRm2MLU"
      }
    }
  ]
}